{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tsunei/anaconda3/envs/tf/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*\n",
    "import os\n",
    "import re\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import keras\n",
    "import warnings\n",
    "from keras.utils import np_utils\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.preprocessing.image import array_to_img, img_to_array, load_img\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.utils import to_categorical\n",
    "from keras.backend import tensorflow_backend\n",
    "from keras import layers\n",
    "from keras import models\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import datasets\n",
    "import scipy.linalg as LA\n",
    "import cv2\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = tf.ConfigProto(gpu_options = tf.GPUOptions(allow_growth = True))\n",
    "session = tf.Session(config = config)\n",
    "tensorflow_backend.set_session(session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_pictures(directory, ext='jpg|jpeg|bmp|png|ppm'):\n",
    "    return [os.path.join(root, f)\n",
    "            for root, _, files in os.walk(directory) for f in files\n",
    "            if re.match(r'([\\w]+\\.(?:' + ext + '))', f.lower())]\n",
    "\n",
    "class ZCAWhitening:\n",
    "  def __init__(self, epsilon=1E-0):\n",
    "    #epsilon=1E-6=81%                                                                         \n",
    "    #espilon=1E-1=88.7%                                                                       \n",
    "    #espilon=1E-0=88.3%                                                                      \n",
    "    #espilon=10=86%                                                                            \n",
    "    self.epsilon = epsilon\n",
    "    self.mean = None\n",
    "    self.zca = None\n",
    "\n",
    "  def fit(self, x):\n",
    "    self.mean = np.mean(x, axis=0)\n",
    "    x_ = x - self.mean\n",
    "    print(x_.shape)\n",
    "    cov = np.dot(x_.T, x_) / x_.shape[0]\n",
    "    E, D, _ = np.linalg.svd(cov)\n",
    "    D = np.sqrt(D) + self.epsilon\n",
    "    self.zca = np.dot(E, np.dot(np.diag(1.0 / D), E.T))\n",
    "    return self\n",
    "\n",
    "  def transform(self, x):\n",
    "    x_ = x - self.mean\n",
    "    return np.dot(x_, self.zca.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "人工物画像のテストデータを取得してます...\n",
      "人工物画像のテストデータを取得しました\n",
      "自然物画像のテストデータを取得してます...\n",
      "自然物画像のテストデータを取得しました\n"
     ]
    }
   ],
   "source": [
    "x = []\n",
    "y = []\n",
    "X_eva = []\n",
    "Y_eva = []\n",
    "\n",
    "print(\"人工物画像のテストデータを取得してます...\")\n",
    "for filepath in list_pictures('../data/CNN_data/test/j_test/'):\n",
    "    warnings.filterwarnings('ignore')\n",
    "    img_eva = img_to_array(load_img(filepath, grayscale=True, target_size=(128, 128))) \n",
    "    X_eva.append(img_eva)\n",
    "    Y_eva.append(0) # 教師データ（正解）\n",
    "\n",
    "\n",
    "print(\"人工物画像のテストデータを取得しました\")\n",
    "\n",
    "    \n",
    "#学習データの取得（非正解画像）\n",
    "print(\"自然物画像のテストデータを取得してます...\")\n",
    "for filepath in list_pictures('../data/CNN_data/test/s_test/'):\n",
    "    img_eva = img_to_array(load_img(filepath, grayscale=True, target_size=(128, 128)))\n",
    "    X_eva.append(img_eva)\n",
    "    Y_eva.append(1) # 教師データ（正解）\n",
    "\n",
    "print(\"自然物画像のテストデータを取得しました\")\n",
    "    \n",
    "x = X_eva\n",
    "y = Y_eva\n",
    "X = X_eva\n",
    "Y = Y_eva\n",
    "# NumPy配列に変換\n",
    "X_eva = np.asarray(X_eva)\n",
    "Y_eva = np.asarray(Y_eva)\n",
    "    \n",
    "#X_eva = X_eva.reshape(X_eva.shape[0], 128, 128)\n",
    "\n",
    "# float32型に変換\n",
    "X_eva = X_eva.astype('float32')\n",
    "\n",
    "# 正規化(0～1)\n",
    "X_eva = X_eva / 255.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x = np.load('test_gray.npy')\n",
    "#X_eva = np.load('test_gray.npy')\n",
    "#Y_eva = np.load('test_label_gray.npy')\n",
    "#print(Y_eva.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000,)\n",
      "テストデータをzca白色化しています...\n",
      "(2000, 128, 128, 1)\n",
      "(2000,)\n",
      "テストデータをzca白色化しました\n"
     ]
    }
   ],
   "source": [
    "print(Y_eva.shape)\n",
    "print(\"テストデータをzca白色化しています...\")\n",
    "#テストデータにzca白色化\n",
    "#x_zcaw_eva = X_eva.reshape(X_eva.shape[0], -1)\n",
    "#zcaw_eva = ZCAWhitening().fit(x_zcaw_eva)\n",
    "#x_zcaw_eva = zcaw_eva.transform(x_zcaw_eva).reshape(X_eva.shape)\n",
    "datagen = ImageDataGenerator(zca_whitening=True)\n",
    "g = datagen.flow(X_eva, Y_eva, X_eva.shape[0], shuffle=False)\n",
    "x_zcaw_eva, Y_eva = g.next()\n",
    "print(x_zcaw_eva.shape)\n",
    "print(Y_eva.shape)\n",
    "print(\"テストデータをzca白色化しました\")\n",
    "  \n",
    "Y_eva = np_utils.to_categorical(Y_eva)\n",
    "np.save('test_label_gray.npy', Y_eva)\n",
    "#x_train, x_test, y_train, y_test = train_test_split(X_white, Y, test_size=0.175)\n",
    "    \n",
    "# 学習用データとテストデータに分割\n",
    "x_test = x_zcaw_eva\n",
    "y_test = Y_eva"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "人工物画像 94.8 %\n",
      "自然物画像 90.4 %\n",
      "全体画像 92.60000000000001 %\n"
     ]
    }
   ],
   "source": [
    "model = load_model('main_gray_temp.h5')\n",
    "batch_size = 128 # バッチサイズ(データサイズ)\n",
    "num_classes = 2 # 分類クラス数(今回は0～9の手書き文字なので10)\n",
    "epochs = 50 # エポック数(学習の繰り返し回数)\n",
    "\n",
    "y_pred = model.predict_classes(x_test)\n",
    "\n",
    "sum_j = 0\n",
    "sum_s = 0\n",
    "for i in range(x_test.shape[0]):\n",
    "    if i < 1000:\n",
    "        if y_pred[i] == 0:\n",
    "            sum_j = sum_j + 1\n",
    "            \n",
    "    else:\n",
    "        if y_pred[i] == 1:\n",
    "            sum_s = sum_s + 1\n",
    "            \n",
    "print(\"人工物画像\",sum_j / 1000 * 100,\"%\")\n",
    "print(\"自然物画像\",sum_s / 1000 * 100,\"%\")\n",
    "print(\"全体画像\",(sum_s + sum_j) / 2000 * 100,\"%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
